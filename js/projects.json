{
	"projects": [{
			"index": "bloomberg",
			"name": "MHCI Capstone + Bloomberg LP",
			"url": "",
			"video":"",
			"description":"",
			"cover": "img\/covers\/b7g.png",
			"tags":"CMU MHCI Capstone project with client Bloomberg LP",
			"previous":"",
			"next":"",
			"year":"2016 / 2017",
			"filters":"development emerging-tech ux-design interaction-design",
			"featured":"inline",
			"color":"#15486a",
			"client":"Bloomberg",
			"role":"Tech Lead",
			"duration":"9 Months",
			"brief":"WORK IN PROGRESS<br><br>This is my capstone project for Carnegie Mellon’s Masters in Human-Computer Interaction. For this project my team worked closely with Bloomberg to try to make financial visualizations more accessible to those who are visually impaired.",
			"content1":"<div class=\"left\"><h1>What am I missing?</h1></div> <div class=\"right\"><p>Visual cues in charts are essential in financial decision-making. The sudden plummet of a stock price, the steady rise of an index fund, the outlier within a sector: these are all visual triggers that sighted finance experts regularly use to identify investment opportunities. <br><br>Because many financial data visualizations lack the necessary alternate text to be read by screen readers, people with visual impairments (PWVI) are at a huge disadvantage when it comes to making financial decisions as crucial information is being withheld. <br><br>For our masters' capstone project, we were asked to explore the domains of finance and visual accessibility, with the goal of giving PWVI better access to financial visualizations. </p></div>",
			"content2":"<div class=\"left\"><h1>Problem Space</h1></div> <div class=\"right\"><p>As a team of five sighted designers, we began by asking ourselves what we could do to learn about the existing abilities and challenges of people with visual impairments. Research has shown a profound disconnect between the perceived and actual abilities of people with visual impairments, finding that sighted workers misjudged the majority of issues that their visually impaired coworkers encounter in the workplace.<br><br>Through interviews with a range of accessibility academics, occupational therapists, and users with visual impairments, we pieced together an understanding of the professional context of visually impaired users. At the same time, we interviewed sighted finance experts to understand the role of visualizations play in the investment decisions they make.</p></div>",
			"content3":"<div class=\"left\"><h1>Our Users</h1></div> <div class=\"right\"><p>Where do workers with visual impairments turn for help? How does it feel for a highly-educated employee to lose their sight in the workplace? What choices do they face?<br><br>For PWVI, asking for help in the workplace often means risking that coworkers will view them as less competent. In addition, sighted coworkers may not always provide the right help as they navigate technologies differently. As a result, many PWVI only turn to help from coworkers as a last resort. As with anyone asking for help, PWVI don’t want to place an unreasonable burden on their social network. When they do need help understanding inaccessible content, they try to return the favor. <br><br><img class=\"nodrop modalize\" src=\"../img/bloomberg/chart1.png\"><br><br>When people lose their sight in the workplace, they face a series of difficult choices. Only 1% of people living with blindness were born without sight, with the majority losing their vision later in life. To understand the context of the 99%, we spoke to many people whose sight declined while they were in the workforce.<br><br>Those who remained employed describe the extraordinary lengths they go to avoid appearing incompetent to sighted coworkers, including hours of invisible work done each week to adapt: extra work that their colleagues don’t see. For others, the struggle to remain in or re-enter the workforce became insurmountable, and they joined the majority of working age blind people who are unemployed. <br><br><img class=\"nodrop modalize\" src=\"../img/bloomberg/chart2.png\"></p></div>",
			"content4":"<div class=\"left\"><h1>Goals</h1></div><div class=\"right\"><p>In our domain analysis, we saw that “people with visual impairments in finance” encompasses people across the spectrums of sight and prior financial knowledge. We scoped our focus to the following goal: <br><br><i>We want to create a user interface to help financially literate people who are blind confidently investigate market trends to identify ideal entry/ exit points for investment decisions. </i><br><br>We scheduled interviews with 16 users: 10 people with blindness who accessed financial data on a regular basis. Five were blind from birth or early childhood, and five blind from degenerative vision loss which advanced later in life. We also spoke with six financial users: four who professionally invest and two who manage personal investments on a regular basis. </p></div>",
			"content5":"<div class=\"left\"><h1>Questions</h1></div><div class=\"right\"><p>Before we could design a user interface, we had to fully understand both the accessibility and financial visualizations domains. Some of our guiding questions for our research process were: <br><br>1) How do people with visual impairments understand and use data? <br><br>2) What data and visualizations are most important to finance experts? <br><br>3) How do people across the sighted spectrum communicate with each other?</p></div>",
			"content6":"<div class=\"left\"><h1>Process</h1></div><div class=\"right\"><p><b>Question Storming:</b> We worked with our client to create a list of questions to set the project scope.<br><br><b>Empathy Exercise:</b> After researching best practices in empathy exercises, we targeted our exercise to familiar finance tasks using a screen reader, creating a protocol designed to reduce prejudice and better understand the barriers that PWVI face. <br><br><b>Literature Review:</b> We read a large assortment of academic research papers on topics ranging from accessibility, vision loss, cognition, and data visualization.<br><br><b>Emerging Tech Survey:</b> We did an emerging technology survey to make sure we were apprised of new technologies that could help our users, such as haptic and tactile interfaces and 3D sound and data sonification experiments.<br><br><b>Early Prototyping:</b> We created early prototypes to explore the forms of potential solutions. We experimented with tactile materials and audio cues, testing internally with blindfold simulation to identify directions for higher fidelity prototyping and user testing.<br><br><b>Expert Interviews:</b> We conducted interviews with accessibility and emerging technology researchers as well as industry accessibility and finance technologists in order to get a better understanding of our problem space.<br><br><b>User Interviews:</b> We conducted six interviews with finance experts and 10 interviews with users who are legally blind, five from birth or childhood and five who lost their sight later in life.<br><br><b>Interpretation Sessions:</b> In order to synthesize findings from our user interviews, we interpreted our notes by modeling user workflows and identifying user breakdowns and attitudes. <br><br><b>Affinity Diagram:</b> From over 600 notes created in our interpretation sessions, we clustered notes into layers of logical groupings developed from the bottom up. Notes were color coded by the user type in order to see which clusters applied to both sighted finance experts and PWVI.<br><br><b>Ideation and Visioning:</b> We extracted insights from our affinity diagram and began ideating on possible solutions.<br><br><b>Prototyping and Testing:</b> We prototyped several low, medium, and high fidelity prototypes and tested them with users to suss out viability and usability.</p></div>",
			"content7":"<div class=\"left\"><h1>Affinity Diagramming Insights</h1></div><div class=\"right\"><p><b>People who help me are interfaces, too.</b><br>The transfer of information by a sighted individual is subject to that person’s interpretation and expertise.<br><br><b>My AT can only provide one piece of info at a time.</b><br>It’s hard to view all parts of the puzzle at once because screen readers only provide one piece of information at a time.<br><br><b>I use charts as a communication tool.</b><br>Highlighting visual cues in charts is the easiest way to persuade colleagues and clients of investment decisions.<br><br><b>There is no normal.</b><br>Both PWVI and finance experts depend on their idiosyncratic workflows to get things done.<br><br><b>Changing tools is hard, so it better be worth it.</b><br>A product must offer a meaningful improvement to justify altering a hard-earned workflow.<br><br><b>I use visuospatial metaphors as mnemonics.</b><br>Visual and spatial reference points help bridge communication between sighted and blind colleagues.</p></div>",
			"content7":"<div class=\"left\"><h1>Team</h1></div><div class=\"right\"><p><img src=\"../img/bloomberg/team.png\" class=\"nodrop\"><br><br>From left to right: Conrad Bassett-Bouchard, Emily Saltz, Nora Tane, Clare Carroll, and Jayanth Prathipati.</p></div>"
		},{
			"index": "robin",
			"name": "Robin",
			"url": "",
			"video":"<iframe src=\"https://player.vimeo.com/video/203604850\" width=\"640\" height=\"360\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description":"",
			"cover": "img\/covers\/robin.png",
			"demo":"../robinprototype",
			"tags":"A conversational UI to enable independence for adults with dementia",
			"previous":"",
			"next":"",
			"year":"2016 / 2017",
			"filters":"ux-design interaction-design emerging-tech",
			"featured":"inline",
			"color":"#73a8ac",
			"role":"High Fidelity Prototyping and Graphic Design Lead",
			"duration":"4 Months",
			"awards":"2nd Place, CHI Student Design Competition",
			"brief":"Robin is a prototype for a conversational UI that works with Amazon Alexa to provide assistance to users with cognitive impairments caused by conditions like dementia. This was my team's submission to the 2017 CHI Student Design Competition. We came in second place out of 70 entries from around the globe.",
			"content1":"<div class=\"left\"><h1>Our Mission</h1></div> <div class=\"right\"><p>From conversations with informal caregivers, we realized that the most impactful thing we can do to help caregivers and adults experiencing cognitive impairment is to use technology in ways that enable them to stay independent for as long as possible.  </p></div>",
			"content4":"<div class=\"left\"><h1>Prototype</h1></div> <div class=\"right\"><p><a target=\"blank\" href=\"../robinprototype\">Live Demo</p><br><img style=\"border: 1px solid #cecece; \"class=\"nodrop\" src=\"../img/robin/prototype.png\"></a></div>",
			"content5":"<div class=\"left\"><h1>Poster Presentation</h1></div> <div class=\"right\"><img class=\"nodrop\"src=\"../img/robin/team.jpg\"><br><p>The team (from left to right): Jayanth Prathipati, Adena Lin, Meg Nidever, Clare Carroll, and Catherine Chiodo (not pictured).</p></div>",
			"content2":"<div class=\"left\"><h1>The Problem</h1></div> <div class=\"right\"><p>Certain things prevent this independence, like needing help with routines and tasks. One user we surveyed said she needed reminders and “help with tasks....like, I have a step by step list to wash my hair...but looking at it while washing my hair is hard, I need something that will talk to me…”<br><br>It’s important to for the rest of us too - 29% of the U.S. population, provide care for a chronically ill, disabled, or aged family member or friend during any given year and spend an average of 20 hours per week providing care for their loved one. </p></div>",
			"content3":"<div class=\"left\"><h1>Why Robin?</h1></div> <div class=\"right\"><p>The use of routines helps users to regain confidence and control over their everyday lives. By alleviating the need for caregiver assistance in the early stages of cognitive decline, Robin allows users to stay self sufficient longer. This in turn allows for a decrease in dependence on loved ones and a reduction in the overwhelming amount of unpaid caregiver work.<br><br>By using Amazon assistant devices, Robin is something that could be on the market in the very near future. At only $50 for an Amazon Dot, users and their loved ones can easily buy these devices, install them, and begin integrating them into their everyday lives.<br><br>On top of this, we found that older-adults already use voice assistants in their day to day activities. In our validation survey after our design phase, one user explicitly said “I have been asking for someone to please make us a programmable Siri.” In addition, 65% of respondents said that they would be interested in trying a device like Robin.<br><br>Because many of Robin’s features are also applicable and useful to those not suffering from cognitive decline, we believe that Robin would be maintained and updated, contrary to many abandoned accessibility tools that were conceived without universal design in mind.<br><br>But most importantly, by offering context-appropriate assistance when the user needs it the most, we believe that Robin would enable users to stay independent for longer and enjoy a better quality of life. </p></div>"
		
		},{
			"index": "datavis",
			"name": "Blissful Careers",
			"url": "",
			"demo": "../datavis",
			"otherbig":"<a href=\"../datavis\" target=\"_blank\" > <img width=\"100%;\" src=\"../img/datavis.png\"></a>",
			"description":"",
			"cover": "img\/covers\/datavis.png",
			"tags":"Three.js and D3.js data visualization to explore company bliss scores.",
			"previous":"",
			"next":"",
			"year":"2017",
			"filters":"ux-design interaction-design emerging-tech",
			"featured":"none",
			"color":"#8ca650",
			"duration":"2 Months",
			"brief":"This is a data visualization / exploration tool to enable the discovery of different factors contributing to companies \"Bliss Scores.\" This was created as an individual final project for a Data Visualization course at CMU.",
			"content1":"<div class=\"left\"><h1>Motivation and Objectives</h1></div> <div class=\"right\"><p>Before this project, I been spending a lot of time trying to figure out where I want to work after finishing school. With so many variables, I found it hard to assess the value and reliability of rankings.<br><Br>I decided to explore the CareerBliss 50 Happiest Companies over the last 5 years to see if I could suss out any insights.</p></div>",
			"content2":"<div class=\"left\"><h1>Data Sets</h1></div> <div class=\"right\"><p>1) Bliss Scores from CareerBliss<br><br>2) Global RepTrak Scores from the Reputation Institute<br><br>3) Company Glass Door Data</p></div>",
			"content3":"<div class=\"left\"><h1>Research Findings</h1></div> <div class=\"right\"><p>After gathering the data in Excel, I made some initial basic graphs and charts to see if I could find and significant trends or other areas of interest.<br><Br>Of the charts I explored, the bubble charts of the Happiness in relation to Salary and the Line graphs of the rankings over time were the most interesting, but due to the amount of data, they were very hard to read.<br><Br><img class=\"nodrop modalize\" src =\"../img/datavis/datavis1.png\"><br><br><img class=\"nodrop modalize\" src =\"../img/datavis/datavis2.png\"><br><br>From this exploration I settled on a new goal: <b>use 3D to make exploring bubble and line graphs together easier in the context of happiness rankings.</b></p></div>",
			"content4":"<div class=\"left\"><h1>Initial Implementation</h1></div> <div class=\"right\"><p>Visualization Tool: Unity3D<br><br>Initially I wanted to create a physical space where users could walk around and explore the data using Unity and the HTC Vive, but I ran into two major issues:<br><br>1) Even though the HTC Vive is a high end VR system, there is still a lot of aliasing on text, making it hard to read large amounts of data<br><br>2) I ran out of real estate quickly. In trying to make the text readable and positioned in logical places for the user to read it, I ran out of places to put information.<br><br><img class=\"nodrop modalize\" src =\"../img/datavis/datavis3.png\"><br><br><img class=\"nodrop modalize\" src =\"../img/datavis/datavis4.png\"></p></div>",
			"content5":"<div class=\"left\"><h1>Final Implementation</h1></div> <div class=\"right\"><p>Visualization Tools: D3 + Three.js<br><br>First, I explored different attributes for the z-axis, the biggest power up of doing the visualization in 3D. What I found is that most of the data that had 2 axes of similarity also had a third, making the increase in readability low.<br><br><img class=\"nodrop modalize\" src=\"../img/datavis/datavis5.png\"><br><br>So instead I used three.js to show a bubble chart of salary and bliss rating with a randomized z-axis for increased readability. I then used D3 to show a line graph of the company’s rank over time in 2D.</p></div>",
			"content6":"<div class=\"left\"><h1>Functionality</h1></div> <div class=\"right\"><p>By clicking on bubbles in either graph, the bubble and the corresponding bubble in the other graph will highlight. Selecting the year in the dropdown on the bubble chart will change the year view, selecting a bubble in a different year column on the line graph will also change the year view. Selecting a different option from the view dropdown will change the perspective. Any company selection will change the corresponding data at the bottom of the page.</p></div>",
			"content7":"<div class=\"left\"><h1>Future Directions</h1></div> <div class=\"right\"><p>If I were to continue the project, I would like to make the visualization responsive on resize, add filters to scope down the data, and add important news stories that may inform the rankings.</p></div>"
		},{
			"index": "holodesign",
			"name": "Design Hololens Sculpture",
			"url": "",
			"video":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/5svRNsW2Fc8\" frameborder=\"0\" allowfullscreen></iframe>",
			"description":"",
			"cover": "img\/covers\/designholo.png",
			"tags":"Perspective typography sculpture made for the hololens.",
			"previous":"",
			"next":"",
			"year":"2017",
			"filters":"ux-design interaction-design emerging-tech",
			"featured":"none",
			"color":"#070909",
			"duration":"2 Months",
			"brief":"This is an exploration into the possibilities and improvements of creating perspective sculptures in virtual reality. This was my final project for a prototyping course at CMU.",
			"content1":"<div class=\"left\"><h1>Inspiration</h1></div> <div class=\"right\"><p>I was inspired by <a href=\"https://www.youtube.com/watch?v=TJ1SDXbij8Y\"> Apple’s Perspective video</a> and the Hololens to explore how perspective sculpture could be procedurally created and interacted with in a virtual environment.<br><br>In creating this experience, I wanted to make sure to leverage the power-ups of creating the sculpture digitally, while maintaining the control the user has to navigate the space and encounter the sculpture.  </p></div>",
			"content2":"<div class=\"left\"><h1>Sketches</h1></div> <div class=\"right\"><p><img class=\"nodrop modalize\" src=\"../img/holodesign/hd3.png\"><br><br>In doing the above sketches, I realized that I wanted to make the letter forms more obscure so that the user has to physically move to the ideal perspective to read the word.</p></div>",
			"content3":"<div class=\"left\"><h1>3D Exploration</h1></div> <div class=\"right\"><p><iframe src=\"https://www.youtube.com/embed/q1SYbNc4EkI\" frameborder=\"0\" allowfullscreen></iframe><br><br>I segmented the word \"design\" in the font Archer and placed the segments as separate sprites into the Unity scene. When the ideal perspective was achieved, the letters locked together, animated, and disappeared.<br><BR><img class=\"nodrop modalize\" src=\"../img/holodesign/hd4.png\"><br><br>I also explored the possibility of placing the letters more abstractly on 3D shapes.</p></div>",
			"content4":"<div class=\"left\"><h1>Typographic Exploration</h1></div> <div class=\"right\"><p><img  class=\"nodrop modalize\" src=\"../img/holodesign/hd5.png\"><br><BR>I did a large typographic exploration to find different letterforms to use in the experience.</p></div>",
			"content5":"<div class=\"left\"><h1>Final Design</h1></div> <div class=\"right\"><p>I took each one of my chosen type faces and broke them up into small pieces and brought them into Unity as sprites. At first I manually scaled and placed the pieces throughout the scene, but I found that this approach made the experience ideal for only users of a particular height. The distortion of the space in Unity was also not the same as in the Hololens, so I decided to assign each segment a random vector at runtime and let it move along that vector based on the distance of a user to a point, regardless of the y coordinate. I deployed the project on the Hololens and demoed it at the course showcase.</p></div>"
		},{
			"index": "maisy",
			"name": "Maisy Mouse AR",
			"url": "https:\/\/www.behance.net\/gallery\/47333721\/Maisy-Mouse-AR",
			"video":"<iframe width=\"100%\" src=\"https://www.youtube.com/embed/VQLr3wcSa_U\" frameborder=\"0\" allowfullscreen></iframe>",
			"description":"<p><br><br>I took a beloved childhood book and thought about how I could give it new life through adding new stories in augmented reality. The application has two parts: the scavenger hunt and the AR playroom.<br><br> The scavenger hunt portion of the application gives users hints and asks them to find and click on different items throughout Maisy's house. To create this, I created Vuforia image targets of items throughout the pop-up book and created corresponding After Effects animations that are played when the image target is in view.<br><br>For the playroom, I surveyed many of Cousins’s books and created different scenes for Maisy and her friends to play in. The purpose of this was to link the many of Cousins’s books to the pop-up books so that users get excited about reading the books and apply what they read about to their playtime. I also created an AR marker for Maisy and one for her friend. By tapping on Maisy, users can cycle between the scene. When this happens, both Maisy and her friends’ costumes change to fit the scene.<\/p>",
			"cover": "img\/covers\/maisy.png",
			"tags":"Augmented reality experience designed to encourage reading. ",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"development emerging-tech ux-design vis-design interaction-design",
			"featured":"inline",
			"color":"#e41e2e",
			"demos":"CMU Design Showcase",
			"duration":"2 Months",
			"brief":"This is an augmented reality scavenger hunt and playroom for Maisy's Pop-up Playhouse by Lucy Cousins made using Unity and Vuforia.",
			"content1":"<div class=\"left\"><h1>About this project</h1></div> <div class=\"right\"><p>I took a beloved childhood book and thought about how I could give it new life through adding new stories in augmented reality. The application has two parts: the scavenger hunt and the AR playroom.<br><br>The scavenger hunt portion of the application gives users hints and asks them to find and click on different items throughout Maisy's house. To create this, I created Vuforia image targets of items throughout the pop-up book and created corresponding After Effects animations that are played when the image target is in view.<br><br>For the playroom, I surveyed many of Cousins’s books and created different scenes for Maisy and her friends to play in. The purpose of this was to link the many of Cousins’s books to the pop-up books so that users get excited about reading the books and apply what they read about to their playtime. I also created an AR marker for Maisy and one for her friend. By tapping on Maisy, users can cycle between the scene. When this happens, both Maisy and her friends’ costumes change to fit the scene.</p></div>",
			"content2":"<div class=\"left\"><h1>CMU Design Showcase</h1></div> <div class=\"right\"><img src=\"../img/maisy1.jpg\" class=\"nodrop  modalize\"><br><br><img src=\"../img/maisy2.jpg\" class=\"nodrop  modalize\"></div>"
		}, {
			"index": "swivel",
			"name": "Swivel",
			"url": "https:\/\/www.behance.net\/gallery\/46479781\/Swivel",
			"video": "<iframe src=\"https://player.vimeo.com/video/196141320\" width=\"640\" height=\"360\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description":"<p><br><br>For this project we were given 5 different kinds of technologies and were asked to pick one and design a product around it. We surveyed each piece of technology and brainstormed possible solutions. After this we determined the idea which we thought was most viable.<br><br>My team chose the connected scale technology and created a product called <i>Swivel<\/i>, an ergonomic office chair. Using the weight sensors in the seat and back, <i>Swivel<\/i> can determine when it is occupied, who is occupying it, and can provide real-time feedback regarding the occupant’s posture.<br><br>Swivel fulfills several needs in commercial office spaces, where poor ergonomics harmfully impact employee health and productivity. Additionally, it provides a rich set of data which employers can use to make their office space more intelligent and adaptive.<br><br>We created a concept video to demonstrate our idea.<\/p>",
			"cover": "img\/covers\/swivel.png",
			"tags":"Concept video for an ergonomic connected office chair.",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"interaction-design ux-design project-management",
			"featured":"inline",
			"color":"#5d6172",
			"duration":"3 Weeks",
			"brief":"This is a product video for a product designed around a connected scale component. This project was created for my Interaction Design Studio course at Carnegie Mellon with Bo Kim and Shannon Sullivan.",
			"content1":"<div class=\"left\"><h1>Prompt</h1></div> <div class=\"right\"><p>For this project we were given 5 different kinds of technologies and were asked to pick one and design a product around it. We surveyed each piece of technology and brainstormed possible solutions. After this we determined the idea which we thought was most viable.</p></div>",
			"content2":"<div class=\"left\"><h1>Our Design</h1></div> <div class=\"right\"><p>My team chose the connected scale technology and created a product called Swivel, an ergonomic office chair. Using the weight sensors in the seat and back, Swivel can determine when it is occupied, who is occupying it, and can provide real-time feedback regarding the occupant’s posture.<br><br>Swivel fulfills several needs in commercial office spaces, where poor ergonomics harmfully impact employee health and productivity. Additionally, it provides a rich set of data which employers can use to make their office space more intelligent and adaptive.<br><br>We created a concept video to demonstrate our idea.</p></div>",
			"content3":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Bo Kim and Shannon Sullivan</p></div>"
		},{
			"index": "holidaycard",
			"name": "360 Holiday Card",
			"url": "https:\/\/www.behance.net\/gallery\/47077635\/360-Holiday-Card",
			"otherbig":"<center><a target=\"_blank\" href=\"http://claremarie.info/christmas2016/desktop.html\"> <img class=\"threesixty\"src=\"../img/cardlinks1.png\" target=\"_blank\"></a> <a target=\"_blank\" href=\"http://claremarie.info/christmas2016/desktop.html\"> <img class=\"threesixty\"src=\"../img/cardlinks2.png\" target=\"_blank\"></a></center>",
			"description": "<p> The prompt was to scope a web-based project that would take three weeks to build and include course topics.<br><br>I used three.js to create a holiday card to send to my family and friends using 360 photos I had taken throughout the year.<br><br>The primary class topic I focused on was library extension. Three.js has a lathe geometry object which takes a set of points and wraps them about an axis to create a geometry. I created an SVG parser which takes an SVG file and extracts the path to automatically create a geometry. This is how I constructed my tree.<br><br>I created the project for cardboard, but created a desktop version as well because of the differing navigational mental models.<\/p>",
			"cover": "img\/covers\/holidaycard.png",
			"tags":"Three.js holiday card made with 360 photos.",
			"previous":"",
			"next":"",
			"year":"2016",
			"demo":"../christmas2016",
			"filters":"development emerging-tech interaction-design ux-design",
			"featured":"inline",
			"color":"#cf514c",
			"duration":"3 Weeks",
			"brief":"This is a 360 photo holiday card I created as my final project for a course at CMU called Software Structures for Usable Interfaces.",
			"content1":"<div class=\"left\"><h1>About the project</h1></div> <div class=\"right\"><p>The prompt was to scope a web-based project that would take three weeks to build and include course topics.<br><br>I used three.js to create a holiday card to send to my family and friends using 360 photos I had taken throughout the year.<br><br>The primary class topic I focused on was library extension. Three.js has a lathe geometry object which takes a set of points and wraps them about an axis to create a geometry. I created an SVG parser which takes an SVG file and extracts the path to automatically create a geometry. This is how I constructed my tree.<br><Br>I created the project for cardboard, but created a desktop version as well because of the differing navigational mental models.</p></div>"
		},{
			"index": "mickeymirror2",
			"name": "Mickey Mirror 2.0",
			"url": "https:\/\/www.behance.net\/gallery\/20538895\/Mickey-Mirror",
			"video":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/McqPx7qup-c\" frameborder=\"0\" allowfullscreen></iframe>",
			"description": "Version 1.0<br><br><p>This is a software mirror I created for an interactive computing course. The prompt was to use video input to create an application.<br><BR>For this project, I wanted to create an experience that could be implemented in a theme park setting. Disneyland has a plethora of different \"ears\" that you can purchase throughout the park, but not all of them are available at each location. The objective of this project was to make an interactive interface that could be installed throughout the park for guests to order any hat and pick it up on their way out.<br><br><\/p><p>Version 2.0</p><br><p>In 2016, I decided to rework this experience as a modular photo booth based on feedback on the original project. I also reworked the codebase to make it easier for others to understand and adapt for their own uses. I was awarded the Delphix Diversity in Technology Scholarship for this piece.<\/p>",
			"cover": "img\/covers\/mickey.png",
			"tags":"Software mirror \/ photo booth for trying on \"mickey ears.\"",
			"previous":"",
			"next":"",
			"year":"2013 / 2016",
			"github":"https://github.com/claremcarroll/Mickey-Mirror-Project",
			"filters":"development ux-design vis-design interaction-design",
			"featured":"none",
			"color":"#c40a0a",
			"awards":"Delphix Diversity in Computing Scholarship",
			"brief":"Mickey Mirror is an interactive software mirror for trying on and emroidering Mickey Mouse \"Ears\" at Disney Parks. The mirror also functions as a photo booth. This project was originally created for an interactive computing course at NYU in 2013.",
			"content1":"<div class=\"left\"><h1>Version 1.0</h1></div> <div class=\"right\"><p>This is a software mirror I created for an interactive computing course. The prompt was to use video input to create an application.<br><BR>For this project, I wanted to create an experience that could be implemented in a theme park setting. Disneyland has a plethora of different \"ears\" that you can purchase throughout the park, but not all of them are available at each location. The objective of this project was to make an interactive interface that could be installed throughout the park for guests to order any hat and pick it up on their way out.</p></div>",
			"content2":"<div class=\"left\"><h1>Version 2.0</h1></div> <div class=\"right\"><p>In 2016, I decided to rework this experience as a modular photo booth based on feedback on the original project. I also reworked the codebase to make it easier for others to understand and adapt for their own uses. I was awarded the Delphix Diversity in Technology Scholarship for this piece.</p></div>"
		}, {
			"index": "vrbfoto",
			"name": "VRB Foto",
			"url": "https://www.behance.net/gallery/47022465/VRB-Foto",
			"description": "<p>I worked on the VRB team at the Samsung accelerator where we created an application for the Gear VR called VRB Foto. I assisted the Project Manager and Creative Director in exploring different user interfaces to interact with the VRB Foto world. Specifically, I worked with the \"grenu,\" VRB Foto's menu system. We wanted to create a menu that could scale easily to add more and more effects. <br><br><img style=\" margin: none; max-width: none;\" width=\"100%\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/1400/58729647022465.58b1ca7c80697.gif\"><br>Get the app <a href=\"https://www.oculus.com/experiences/gear-vr/1297827283571813/\">here</a>.<br><br>I also designed the web portal for VRB Foto which you can view <a href=\"http://vrbfoto.com/\">here</a>. The most challenging part about the web portal was deciding how users would preview photospheres. This is the interaction I designed and implemented for the website:<br><br><img width=\"100%\" style=\" margin: none; max-width: none;\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/max_1200/dc414d47022465.586df3e56456e.gif\"></p>",
			"cover": "img\/covers\/vrbfoto.png",
			"tags":"VRB Foto 360 photo sharing application for the Gear VR.",
			"previous":"",
			"next":"",
			"year":"2016",
			"productpage":"https://www.oculus.com/experiences/gear-vr/1297827283571813/",
			"demo":"../vrbis",
			"filters":"ux-design vis-design ux-design interaction-design emerging-tech development",
			"featured":"inline",
			"color":"#be7cb5",
			"company":"VRB / Samsung Accelerator",
			"role":"VR Generalist",
			"brief":"VRB Foto is a 360 Photo viewer that allows users to share and augment their photos. ",
			"content1":"<div class=\"left\"><h1>Grenu</h1></div> <div class=\"right\"><p>I worked on the VRB team at the Samsung accelerator (now known as Samsung Next) where we created an application for the Gear VR called VRB Foto. I assisted the Project Manager and Creative Director in exploring different user interfaces to interact with the VRB Foto world. Specifically, I worked with the \"grenu,\" VRB Foto's menu system. We wanted to create a menu that could scale easily to add more and more effects.<br><br><img class=\"nodrop modalize\" src=\"../img/foto1.gif\"></p></div>",
			"content2":"<div class=\"left\"><h1>Website</h1></div> <div class=\"right\"><p>I also designed the web portal for VRB Foto which you can view here. The most challenging part about the web portal was deciding how users would preview photospheres.</p></div>",
			"content3":"<div class=\"left\"><h1></h1></div> <div class=\"right\"><img class=\"nodrop modalize\" src=\"../img/foto2.gif\"></div>",
			"content4":"<div class=\"left\"><h1>Acquisition</h1></div> <div class=\"right\"><p>The VRB team was recently acquired by Samsung proper and has now relocated to San Francisco. Read more details <a href=\"https://techcrunch.com/2017/06/16/samsung-quietly-acquired-vr-app-studio-vrb-sources-say-for-5-5m/\">here</a></p></div>"
		}, {
			"index": "blue",
			"name": "Body Labs Blue",
			"url": "https:\/\/www.behance.net\/gallery\/41917453\/Body-Labs-Blue",
			"productpage": "https://www.bodylabs.com/solutions/spectrum/blue/",
			"video":"<iframe src=\"https:\/\/www.youtube.com\/embed\/33qBnhdWQ7w\" frameborder=\"0\" allowfullscreen><\/iframe>",
			"description": "<br><br><p>Although we want users to trust our predictive algorithm, we also want to enable them to add more specific information accurately. <br><br><center><a target=\"_blank\" href=\"https:\/\/www.bodylabs.com\/solutions\/spectrum\/blue\/\">View Blue Here<\/a><\/center><br><br><img class=\"fullw\" src=\"http:\/\/claremarie.info\/img\/portfolio\/blscreenshot.png\"><\/p>",
			"cover": "img\/covers\/blue.png",
			"tags":"Interface for creating virtual bodies from measurements.",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"ux-design interaction-design",
			"featured":"none",
			"color":"#28b2c9",
			"company":"Body Labs",
			"role":"UX/UI Designer and Developer",
			"duration":"4 Months",
			"brief":"This is a project I lead as a UX Designer at Body Labs. Essentially, Body Labs Blue is a tool for creating custom clothing through six key measurements. The main goal of this product is to allow users to feel confident buying custom clothing when entering only a few measurements.",
			"content1":"<div class=\"left\"><h1>Product Description</h1></div> <div class=\"right\"><p>Through an easily embedded Web interface, Body Labs Blue uses artificial intelligence (AI) and machine learning algorithms to reference just the height and weight of your customers to predict 19 highly accurate additional measurements ideal for custom clothing or sizing recommendations. To help ensure accuracy, your customers can also refine six-key measurements predicted by Blue. This enables your business to deliver clothing customization and standardization that scales for any purchase volume or web traffic.</p></div>",
			"content3":"<div class=\"left\"><h1>Product Demo</h1></div> <div class=\"right\"><video controls loop autoplay width=\"100%\"><source src=\"../video/blue.mp4\" type=\"video/mp4\"></div>",
			"content2":"<div class=\"left\"><h1>Prototypes</h1></div> <div class=\"right\"><video controls loop autoplay width=\"100%\"><source src=\"../video/blueprototypes.mp4\" type=\"video/mp4\"></div>"
		}, {
			"index": "holojam",
			"name": "Holojam",
			"url": "https:\/\/www.behance.net\/gallery\/35388195\/Holojam",
			"video":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/zB9Vw1vPo20\" frameborder=\"0\" allowfullscreen></iframe>",
			"description": "<p><br><center><a href=\"http:\/\/mrlholojam.tumblr.com\">Official Website<\/a><\/center>",
			"cover": "img\/covers\/holojam.png",
			"tags":"Multi-user VR drawing experience.",
			"previous":"",
			"next":"",
			"year":"2015",
			"filters":"project-management ux-design emerging-tech",
			"featured":"none",
			"color":"#9974af",
			"role":"User Experience Designer",
			"group":"NYU Media Research Lab",
			"demos":"SIGGRAPH 2015",
			"brief":"This is an experience I helped design and manage at the NYU Media Research Lab under Ken Perlin. We created an experience where up to five people can draw in virtual reality together.",
			"content1":"<div class=\"left\"><h1>About the Experience</h1></div> <div class=\"right\"><p>Up to five people share virtual space with untethered headsets and see each other as stylized avatars. They draw shapes in the air with their magic wands and contribute to a persistent three-dimensional sculptural art-work. <a href=\"http://mrlholojam.tumblr.com/detailed-description\">Full Description Here</a></p></div>",
			"content2":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Connor Defanti, Zach Cimafonte, Laura Juo-Hsin Chen, Sebastian Herscher, Will Field-Thompson, Daren Liu, David Lobser, Ken Perlin.</p></div>",
			"content3":"<div class=\"left\"><h1>Press</h1></div> <div class=\"right\"><p>Motherboard, MIT Technology Review, UploadVR, WSN, VRR</p></div>"
		}, {
			"index": "bodylabsvr",
			"name": "Body Labs VR Demo",
			"url": "https:\/\/www.behance.net\/gallery\/35388107\/Body-Labs-VR-Demo",
			"video":"<iframe src=\"https://player.vimeo.com/video/160151843\" width=\"500\" height=\"282\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>This is an experience I created for Body Labs for CES 2015. The goal was to demonstrate the value of our Body Model through multiple visualizations. I created the application in Unity for cardboard and created animated models by applying motion capture data to some of our Body Models.<\/p>",
			"cover": "img\/covers\/bodylabsvr.png",
			"tags":"VR demo for CES 2015.",
			"previous":"",
			"next":"",
			"year":"2015",
			"filters":"development ux-design interaction-design emerging-tech",
			"featured":"none",
			"color":"#070909",
			"company":"Body Labs",
			"role":"UX/UI Designer and Developer",
			"demos":"CES 2015",
			"brief":"This is a application created to provide mobile demos at CES 2015.",
			"content1":"<div class=\"left\"><h1>About the Experience</h1></div> <div class=\"right\"><p>This demo puts the user in a room where there is different information on each of the 4 walls. First, you see the Body Labs logo. Rotating to the left, you see a Body Labs Body Model displaying the models potential for use in creating custom clothing. Next, you see a series of flat animations which display the possibilities of Body Labs software. Finally, you see a variety of body models in different shapes and sizes with applied motion capture sequences.</p><br><p>This demo was meant to showcases the different aspects and possibilities of Body Labs.</p></div>",
			"content2":"<div class=\"left\"><h1>Challenges</h1></div> <div class=\"right\"><p>For this project, we had to create something to showcase many aspects of our platform while remaining mobile. We also had to limit the amount of motion in order to ensure the safety of standing users.</p></div>"
		}, {
			"index": "motivate",
			"name": "Motivate - Body Labs Hackathon Submission",
			"url": "https:\/\/www.behance.net\/gallery\/25338009\/Motivate-Body-Labs-Hackathon-Submission",
			"video":"<iframe src=\"https://player.vimeo.com/video/123574576\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>This is my team's submission for the Body Labs Hackathon @ NYU with Yoland Yan and Chris Jimenez. This project was done over the course of 10 hours and landed me a UX position at Body Labs. Motivate is a social fitness platform which utilizes body scanning to help you explore the fitness routines of individuals with similar body shapes.<br><br>Check out the interactive demo <a href=\"https:\/\/marvelapp.com\/c7ah14g\/screen\/21277833\">here<\/a>.<\/p>",
			"cover": "img\/covers\/motivate.jpg",
			"tags":"Mobile UI for a social fitness platform.",
			"previous":"",
			"next":"",
			"year":"2015",
			"filters":"ux-design vis-design interaction-design project-management",
			"featured":"none",
			"color":"#383b46",
			"duration":"10 Hours",
			"brief":"This was my team's submission for the Body Labs Hackathon @ NYU. This project was done over the course of 10 hours and landed me a UX/UI position at Body Labs from 2015-2016. Check out the demo <a target=\"_blank\" href=\"https://marvelapp.com/c7ah14g/screen/21277833\">here</a>.",
			"content1":"<div class=\"left\"><h1>Screens</h1></div> <div class=\"right\"><img class=\"nodrop modalize\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/1400/fd7fd425338009.5877d5963e673.png\"></div>",
			"content2":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Chris Jimenez and Yoland Yan.</p></div>"
		}, {
			"index": "cgpottery",
			"name": "CG Pottery",
			"url": "https:\/\/www.behance.net\/gallery\/35401589\/CG-Pottery",
			"video":"<iframe src=\"https://player.vimeo.com/video/115201450\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>This is a project I created with Sebastian Herscher for Ken Perlin’s Computer Graphics course. The project consists of two pieces: both centered on creating lathe geometries, much like pottery! The first piece is a Leap Motion application that creates virtual pottery based on lines drawn in the air by pinching two of your fingers together. The second piece creates the geometries through drawing with a mouse and creates a 3D printable file.<\/p>",
			"cover": "img\/covers\/pottery.png",
			"tags":"Virtual pottery creation tool using the Leap Motion.",
			"previous":"",
			"next":"",
			"year":"2014",
			"github":"https://github.com/claremcarroll/PotteryProcessing",
			"filters":"development ux-design interaction-design emerging-tech",
			"featured":"none",
			"color":"#3e9dab",
			"brief":"This is a 3D Pottery creation tool using the Leap Motion.",
			"content1":"<div class=\"left\"><h1>Prompt</h1></div> <div class=\"right\"><p>This was my final project for Ken Perlin's Computer Graphics course. The prompt was very open ended, so Sebastian and I decided to create a mid-air pottery creation tool that could create artwork to be 3D printed.</p></div>",
			"content2":"<div class=\"left\"><h1>Final Project</h1></div> <div class=\"right\"><p>Due to time constraints, we broke the project into two pieces: 1. A Leap Motion driven Processing sketch to simulate the creation of mid-air pottery and 2. a web drawing framework to enable the creation of ready-to-be-printed 3D models.</p></div>",
			"content3":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Sebastian Herscher</p></div>"
		},{
			"index": "aralphabet",
			"name": "Augmented Reality Alphabet",
			"url": "https:\/\/www.behance.net\/gallery\/20632059\/Augmented-Reality-Alphabet",
			"video":"<iframe src=\"https://player.vimeo.com/video/109347305\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>An augmented reality alphabet designed to make it fun to learn how to spell</p>",
			"cover": "img\/covers\/aralphabet.png",
			"tags":"Augmented reality alphabet designed to help children learn how to spell.",
			"previous":"",
			"next":"",
			"year":"2014",
			"github":"https://github.com/claremcarroll/ARAlphabet",
			"filters":"development ux-design emerging-tech interaction-design",
			"featured":"none",
			"color":"#abb2da",
			"brief":"This is an augmented reality alphabet designed to make it fun to learn the alphabet. I designed the font, letter models, and all AR markers by hand. In a later iteration of this project, I made it so if a logical word was made with the letters, the definition would appear.",
			"content1":"<div class=\"left\"><h1>Prompt</h1></div> <div class=\"right\"><p>This project was originally created for a design course at NYU. The prompt was to create an alphabet. I used this project to explore the limitations of augmented reality markers and Processing's capability to render 3D models.</p></div>",
			"content2":"<div class=\"left\"><h1>Markers</h1></div> <div class=\"right\"><img class=\"nodrop modalize\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/1400/5360ca20632059.58700dcee8edc.png\"></div>"
		},{
			"index": "genesisdiyed",
			"name": "Genesis DIYed",
			"url": "https:\/\/www.behance.net\/gallery\/20539775\/Genesis-DIYed",
			"video":"<iframe src=\"https://player.vimeo.com/video/81892131\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>A redundant augmented reality board project in which users can draw their own characters and scan them into a 3D universe. Built with Yuji Tsuchikawa and Rock Zou. Presented at the ITP Winter Showcase in 2013.</p>",
			"cover": "img\/covers\/genesis.png",
			"tags":"Augmented reality virtual universe created by drawing and scanning in characters.",
			"previous":"",
			"next":"",
			"year":"2013",
			"filters":"project-management development ux-design interaction-design emerging-tech",
			"featured":"none",
			"color":"#000000",
			"role":"Interaction Design, 3D Modelling, and Graphics Lead.",
			"demos":"ITP Winter Showcase 2013",
			"brief":"This is a redundant augmented reality board project in which users can draw their own characters and scan them into a 3D universe. Using specified augmented reality markers, users can also zoom in on their characters and plant trees around the universe. ",
			"content1":"<div class=\"left\"><h1>Concept</h1></div> <div class=\"right\"><p>As children, we loved to draw, but it was hard to play with our drawings because they were stuck on a sheet of paper. We decided to create an interface that changes the way users interact with their drawings: users draw characters on to paper, the programs puts them into an augmented reality universe of their own which the users can alter by hand in real time and watch the \"Paper Mario\" versions of their hand-drawn creations react accordingly.</p><br><p>This project attempts to better connect the user and the augmented reality by giving the user the 'god-like' ability to actually create a miniature world in augmented reality. The process resembles the stories in Genesis where god 'makes up' everything and places it into the world. </p><br><p>First, an empty AR world is projected onto a 1 x 1 ft board. Then, users can draw shapes on paper and select what objects(animals, plants, cars, user themselves, etc.) this shape represents. Drawings are then captured by the camera, encoded with pre-written AI, and projected as movable onto the augmented reality. Users can also change the geography of the world by placing different AR markers onto the board. The objects are able to respond to the geography and interact with other objects, just like in the real world.</p></div>",
			"content2":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Yuji Tsuchikawa and Rock Zou</p></div>"
		},{
			"index": "graphicdesign",
			"name": "Misc Graphic Design",
			"url": "",
			"video":"",
			"description": "",
			"cover": "img\/covers\/graphicdesign.png",
			"tags":"Miscellaneous graphic design projects.",
			"previous":"",
			"next":"",
			"year":"Various",
			"filters":"vis-design",
			"featured":"none",
			"color":"#c4315f",
			"client":"Misc.",
			"brief":"These are some of my favorite graphic design projects I have done over the years.",
			"content1":"<div class=\"left\"><h1>VRCade @ Barcade</h1><p>Advertisement for event at the Samsung Accelerator.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/1.png\"></div>",
			"content2":"<div class=\"left\"><h1>Spotlight Mailer</h1><p>Advertisement for the 2014 Spotlight competition.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/2.png\"></div>",
			"content3":"<div class=\"left\"><h1>Globall Artwork</h1><p>Artwork for the NYU Welcome Week Dance Globall.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/3.png\"></div>",
			"content4":"<div class=\"left\"><h1>Just Keep Swimming</h1><p>Personal project.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/4.png\"></div>",
			"content5":"<div class=\"left\"><h1>UVL Postcard</h1><p>Advertisement for NYU's full school Ultra Violet Live talent show.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/5.jpg\"></div>",
			"content6":"<div class=\"left\"><h1>Day of Service Poster</h1><p>For NYU's Inter-Residence Hall Council.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/6.jpg\"></div>",
			"content7":"<div class=\"left\"><h1>Elephant Doodle</h1><p>Personal Project.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/7.png\"></div>"

			
		}

	]

}