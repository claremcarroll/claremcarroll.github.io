{
	"projects": [{
			"index": "bloomberg",
			"name": "MHCI Capstone + Bloomberg LP",
			"url": "",
			"video":"",
			"description":"",
			"cover": "img\/covers\/b7g.png",
			"tags":"CMU MHCI Capstone project with client Bloomberg LP",
			"previous":"",
			"next":"",
			"year":"2016 / 2017",
			"filters":"development emerging-tech ux-design interaction-design",
			"featured":"inline",
			"color":"#15486a",
			"client":"Bloomberg",
			"role":"Tech Lead",
			"duration":"9 Months",
			"brief":"WORK IN PROGRESS<br><br>This is my capstone project for Carnegie Mellon’s Masters in Human-Computer Interaction. For this project my team worked closely with Bloomberg to try to make financial visualizations more accessible to those who are visually impaired.",
			"content1":"<div class=\"left\"><h1>What am I missing?</h1></div> <div class=\"right\"><p>Visual cues in charts are essential in financial decision-making. The sudden plummet of a stock price, the steady rise of an index fund, the outlier within a sector: these are all visual triggers that sighted finance experts regularly use to identify investment opportunities. <br><br>Because many financial data visualizations lack the necessary alternate text to be read by screen readers, people with visual impairments (PWVI) are at a huge disadvantage when it comes to making financial decisions as crucial information is being withheld. <br><br>For our masters' capstone project, we were asked to explore the domains of finance and visual accessibility, with the goal of giving PWVI better access to financial visualizations. </p></div>",
			"content2":"<div class=\"left\"><h1>Problem Space</h1></div> <div class=\"right\"><p>As a team of five sighted designers, we began by asking ourselves what we could do to learn about the existing abilities and challenges of people with visual impairments. Research has shown a profound disconnect between the perceived and actual abilities of people with visual impairments, finding that sighted workers misjudged the majority of issues that their visually impaired coworkers encounter in the workplace.<br><br>Through interviews with a range of accessibility academics, occupational therapists, and users with visual impairments, we pieced together an understanding of the professional context of visually impaired users. At the same time, we interviewed sighted finance experts to understand the role of visualizations play in the investment decisions they make.</p></div>",
			"content3":"<div class=\"left\"><h1>Our Users</h1></div> <div class=\"right\"><p>Where do workers with visual impairments turn for help? How does it feel for a highly-educated employee to lose their sight in the workplace? What choices do they face?<br><br>For PWVI, asking for help in the workplace often means risking that coworkers will view them as less competent. In addition, sighted coworkers may not always provide the right help as they navigate technologies differently. As a result, many PWVI only turn to help from coworkers as a last resort. As with anyone asking for help, PWVI don’t want to place an unreasonable burden on their social network. When they do need help understanding inaccessible content, they try to return the favor. <br><br><img class=\"nodrop modalize\" src=\"../img/bloomberg/chart1.png\"><br><br>When people lose their sight in the workplace, they face a series of difficult choices. Only 1% of people living with blindness were born without sight, with the majority losing their vision later in life. To understand the context of the 99%, we spoke to many people whose sight declined while they were in the workforce.<br><br>Those who remained employed describe the extraordinary lengths they go to avoid appearing incompetent to sighted coworkers, including hours of invisible work done each week to adapt: extra work that their colleagues don’t see. For others, the struggle to remain in or re-enter the workforce became insurmountable, and they joined the majority of working age blind people who are unemployed. <br><br><img class=\"nodrop modalize\" src=\"../img/bloomberg/chart2.png\"></p></div>",
			"content4":"<div class=\"left\"><h1>Goals</h1></div><div class=\"right\"><p>In our domain analysis, we saw that “people with visual impairments in finance” encompasses people across the spectrums of sight and prior financial knowledge. We scoped our focus to the following goal: <br><br><i>We want to create a user interface to help financially literate people who are blind confidently investigate market trends to identify ideal entry/ exit points for investment decisions. </i><br><br>We scheduled interviews with 16 users: 10 people with blindness who accessed financial data on a regular basis. Five were blind from birth or early childhood, and five blind from degenerative vision loss which advanced later in life. We also spoke with six financial users: four who professionally invest and two who manage personal investments on a regular basis. </p></div>",
			"content5":"<div class=\"left\"><h1>Questions</h1></div><div class=\"right\"><p>Before we could design a user interface, we had to fully understand both the accessibility and financial visualizations domains. Some of our guiding questions for our research process were: <br><br>1) How do people with visual impairments understand and use data? <br><br>2) What data and visualizations are most important to finance experts? <br><br>3) How do people across the sighted spectrum communicate with each other?</p></div>",
			"content6":"<div class=\"left\"><h1>Process</h1></div><div class=\"right\"><p><b>Question Storming:</b> We worked with our client to create a list of questions to set the project scope.<br><br><b>Empathy Exercise:</b> After researching best practices in empathy exercises, we targeted our exercise to familiar finance tasks using a screen reader, creating a protocol designed to reduce prejudice and better understand the barriers that PWVI face. <br><br><b>Literature Review:</b> We read a large assortment of academic research papers on topics ranging from accessibility, vision loss, cognition, and data visualization.<br><br><b>Emerging Tech Survey:</b> We did an emerging technology survey to make sure we were apprised of new technologies that could help our users, such as haptic and tactile interfaces and 3D sound and data sonification experiments.<br><br><b>Early Prototyping:</b> We created early prototypes to explore the forms of potential solutions. We experimented with tactile materials and audio cues, testing internally with blindfold simulation to identify directions for higher fidelity prototyping and user testing.<br><br><b>Expert Interviews:</b> We conducted interviews with accessibility and emerging technology researchers as well as industry accessibility and finance technologists in order to get a better understanding of our problem space.<br><br><b>User Interviews:</b> We conducted six interviews with finance experts and 10 interviews with users who are legally blind, five from birth or childhood and five who lost their sight later in life.<br><br><b>Interpretation Sessions:</b> In order to synthesize findings from our user interviews, we interpreted our notes by modeling user workflows and identifying user breakdowns and attitudes. <br><br><b>Affinity Diagram:</b> From over 600 notes created in our interpretation sessions, we clustered notes into layers of logical groupings developed from the bottom up. Notes were color coded by the user type in order to see which clusters applied to both sighted finance experts and PWVI.<br><br><b>Ideation and Visioning:</b> We extracted insights from our affinity diagram and began ideating on possible solutions.<br><br><b>Prototyping and Testing:</b> We prototyped several low, medium, and high fidelity prototypes and tested them with users to suss out viability and usability.</p></div>",
			"content7":"<div class=\"left\"><h1>Affinity Diagramming Insights</h1></div><div class=\"right\"><p><b>People who help me are interfaces, too.</b><br>The transfer of information by a sighted individual is subject to that person’s interpretation and expertise.<br><br><b>My AT can only provide one piece of info at a time.</b><br>It’s hard to view all parts of the puzzle at once because screen readers only provide one piece of information at a time.<br><br><b>I use charts as a communication tool.</b><br>Highlighting visual cues in charts is the easiest way to persuade colleagues and clients of investment decisions.<br><br><b>There is no normal.</b><br>Both PWVI and finance experts depend on their idiosyncratic workflows to get things done.<br><br><b>Changing tools is hard, so it better be worth it.</b><br>A product must offer a meaningful improvement to justify altering a hard-earned workflow.<br><br><b>I use visuospatial metaphors as mnemonics.</b><br>Visual and spatial reference points help bridge communication between sighted and blind colleagues.</p></div>",
			"content7":"<div class=\"left\"><h1>Team</h1></div><div class=\"right\"><p><img src=\"../img/bloomberg/team.png\" class=\"nodrop\"><br><br>From left to right: Conrad Bassett-Bouchard, Emily Saltz, Nora Tane, Clare Carroll, and Jayanth Prathipati.</p></div>"
		},{
			"index": "robin",
			"name": "Robin",
			"url": "",
			"video":"<iframe src=\"https://player.vimeo.com/video/203604850\" width=\"640\" height=\"360\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description":"",
			"cover": "img\/covers\/robin.png",
			"demo":"../robinprototype",
			"tags":"A conversational UI to enable independence for adults with dementia",
			"previous":"",
			"next":"",
			"year":"2016 / 2017",
			"filters":"ux-design interaction-design emerging-tech",
			"featured":"inline",
			"color":"#73a8ac",
			"role":"High Fidelity Prototyping and Graphic Design Lead",
			"duration":"4 Months",
			"awards":"2nd Place, CHI Student Design Competition",
			"brief":"Robin is a prototype for a conversational UI that works with Amazon Alexa to provide assistance to users with cognitive impairments caused by conditions like dementia. This was my team's submission to the 2017 CHI Student Design Competition. We came in second place out of 70 entries from around the globe.",
			"content1":"<div class=\"left\"><h1>Our Mission</h1></div> <div class=\"right\"><p>From conversations with informal caregivers, we realized that the most impactful thing we can do to help caregivers and adults experiencing cognitive impairment is to use technology in ways that enable them to stay independent for as long as possible.  </p></div>",
			"content4":"<div class=\"left\"><h1>Prototype</h1></div> <div class=\"right\"><p><a target=\"blank\" href=\"../robinprototype\">Live Demo</p><br><img style=\"border: 1px solid #cecece; \"class=\"nodrop\" src=\"../img/robin/prototype.png\"></a></div>",
			"content5":"<div class=\"left\"><h1>Poster Presentation</h1></div> <div class=\"right\"><img class=\"nodrop\"src=\"../img/robin/team.jpg\"><br><p>The team (from left to right): Jayanth Prathipati, Adena Lin, Meg Nidever, Clare Carroll, and Catherine Chiodo (not pictured).</p></div>",
			"content2":"<div class=\"left\"><h1>The Problem</h1></div> <div class=\"right\"><p>Certain things prevent this independence, like needing help with routines and tasks. One user we surveyed said she needed reminders and “help with tasks....like, I have a step by step list to wash my hair...but looking at it while washing my hair is hard, I need something that will talk to me…”<br><br>It’s important to for the rest of us too - 29% of the U.S. population, provide care for a chronically ill, disabled, or aged family member or friend during any given year and spend an average of 20 hours per week providing care for their loved one. </p></div>",
			"content3":"<div class=\"left\"><h1>Why Robin?</h1></div> <div class=\"right\"><p>The use of routines helps users to regain confidence and control over their everyday lives. By alleviating the need for caregiver assistance in the early stages of cognitive decline, Robin allows users to stay self sufficient longer. This in turn allows for a decrease in dependence on loved ones and a reduction in the overwhelming amount of unpaid caregiver work.<br><br>By using Amazon assistant devices, Robin is something that could be on the market in the very near future. At only $50 for an Amazon Dot, users and their loved ones can easily buy these devices, install them, and begin integrating them into their everyday lives.<br><br>On top of this, we found that older-adults already use voice assistants in their day to day activities. In our validation survey after our design phase, one user explicitly said “I have been asking for someone to please make us a programmable Siri.” In addition, 65% of respondents said that they would be interested in trying a device like Robin.<br><br>Because many of Robin’s features are also applicable and useful to those not suffering from cognitive decline, we believe that Robin would be maintained and updated, contrary to many abandoned accessibility tools that were conceived without universal design in mind.<br><br>But most importantly, by offering context-appropriate assistance when the user needs it the most, we believe that Robin would enable users to stay independent for longer and enjoy a better quality of life. </p></div>"
		
		},{
			"index": "maisy",
			"name": "Maisy Mouse AR",
			"url": "https:\/\/www.behance.net\/gallery\/47333721\/Maisy-Mouse-AR",
			"video":"<iframe width=\"100%\" src=\"https://www.youtube.com/embed/VQLr3wcSa_U\" frameborder=\"0\" allowfullscreen></iframe>",
			"description":"<p><br><br>I took a beloved childhood book and thought about how I could give it new life through adding new stories in augmented reality. The application has two parts: the scavenger hunt and the AR playroom.<br><br> The scavenger hunt portion of the application gives users hints and asks them to find and click on different items throughout Maisy's house. To create this, I created Vuforia image targets of items throughout the pop-up book and created corresponding After Effects animations that are played when the image target is in view.<br><br>For the playroom, I surveyed many of Cousins’s books and created different scenes for Maisy and her friends to play in. The purpose of this was to link the many of Cousins’s books to the pop-up books so that users get excited about reading the books and apply what they read about to their playtime. I also created an AR marker for Maisy and one for her friend. By tapping on Maisy, users can cycle between the scene. When this happens, both Maisy and her friends’ costumes change to fit the scene.<\/p>",
			"cover": "img\/covers\/maisy.png",
			"tags":"Augmented reality experience designed to encourage reading. ",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"development emerging-tech ux-design vis-design interaction-design",
			"featured":"inline",
			"color":"#e41e2e",
			"demos":"CMU Design Showcase",
			"duration":"2 Months",
			"brief":"This is an augmented reality scavenger hunt and playroom for Maisy's Pop-up Playhouse by Lucy Cousins made using Unity and Vuforia.",
			"content1":"<div class=\"left\"><h1>About this project</h1></div> <div class=\"right\"><p>I took a beloved childhood book and thought about how I could give it new life through adding new stories in augmented reality. The application has two parts: the scavenger hunt and the AR playroom.<br><br>The scavenger hunt portion of the application gives users hints and asks them to find and click on different items throughout Maisy's house. To create this, I created Vuforia image targets of items throughout the pop-up book and created corresponding After Effects animations that are played when the image target is in view.<br><br>For the playroom, I surveyed many of Cousins’s books and created different scenes for Maisy and her friends to play in. The purpose of this was to link the many of Cousins’s books to the pop-up books so that users get excited about reading the books and apply what they read about to their playtime. I also created an AR marker for Maisy and one for her friend. By tapping on Maisy, users can cycle between the scene. When this happens, both Maisy and her friends’ costumes change to fit the scene.</p></div>",
			"content2":"<div class=\"left\"><h1>CMU Design Showcase</h1></div> <div class=\"right\"><img src=\"../img/maisy1.jpg\" class=\"nodrop  modalize\"><br><br><img src=\"../img/maisy2.jpg\" class=\"nodrop  modalize\"></div>"
		}, {
			"index": "swivel",
			"name": "Swivel",
			"url": "https:\/\/www.behance.net\/gallery\/46479781\/Swivel",
			"video": "<iframe src=\"https://player.vimeo.com/video/196141320\" width=\"640\" height=\"360\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description":"<p><br><br>For this project we were given 5 different kinds of technologies and were asked to pick one and design a product around it. We surveyed each piece of technology and brainstormed possible solutions. After this we determined the idea which we thought was most viable.<br><br>My team chose the connected scale technology and created a product called <i>Swivel<\/i>, an ergonomic office chair. Using the weight sensors in the seat and back, <i>Swivel<\/i> can determine when it is occupied, who is occupying it, and can provide real-time feedback regarding the occupant’s posture.<br><br>Swivel fulfills several needs in commercial office spaces, where poor ergonomics harmfully impact employee health and productivity. Additionally, it provides a rich set of data which employers can use to make their office space more intelligent and adaptive.<br><br>We created a concept video to demonstrate our idea.<\/p>",
			"cover": "img\/covers\/swivel.png",
			"tags":"Concept video for an ergonomic connected office chair.",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"interaction-design ux-design project-management",
			"featured":"inline",
			"color":"#5d6172",
			"duration":"3 Weeks",
			"brief":"This is a product video for a product designed around a connected scale component. This project was created for my Interaction Design Studio course at Carnegie Mellon with Bo Kim and Shannon Sullivan.",
			"content1":"<div class=\"left\"><h1>Prompt</h1></div> <div class=\"right\"><p>For this project we were given 5 different kinds of technologies and were asked to pick one and design a product around it. We surveyed each piece of technology and brainstormed possible solutions. After this we determined the idea which we thought was most viable.</p></div>",
			"content2":"<div class=\"left\"><h1>Our Design</h1></div> <div class=\"right\"><p>My team chose the connected scale technology and created a product called Swivel, an ergonomic office chair. Using the weight sensors in the seat and back, Swivel can determine when it is occupied, who is occupying it, and can provide real-time feedback regarding the occupant’s posture.<br><br>Swivel fulfills several needs in commercial office spaces, where poor ergonomics harmfully impact employee health and productivity. Additionally, it provides a rich set of data which employers can use to make their office space more intelligent and adaptive.<br><br>We created a concept video to demonstrate our idea.</p></div>",
			"content3":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Bo Kim and Shannon Sullivan</p></div>"
		}, {
			"index": "vrbfoto",
			"name": "VRB Foto",
			"url": "https://www.behance.net/gallery/47022465/VRB-Foto",
			"description": "<p>I worked on the VRB team at the Samsung accelerator where we created an application for the Gear VR called VRB Foto. I assisted the Project Manager and Creative Director in exploring different user interfaces to interact with the VRB Foto world. Specifically, I worked with the \"grenu,\" VRB Foto's menu system. We wanted to create a menu that could scale easily to add more and more effects. <br><br><img style=\" margin: none; max-width: none;\" width=\"100%\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/1400/58729647022465.58b1ca7c80697.gif\"><br>Get the app <a href=\"https://www.oculus.com/experiences/gear-vr/1297827283571813/\">here</a>.<br><br>I also designed the web portal for VRB Foto which you can view <a href=\"http://vrbfoto.com/\">here</a>. The most challenging part about the web portal was deciding how users would preview photospheres. This is the interaction I designed and implemented for the website:<br><br><img width=\"100%\" style=\" margin: none; max-width: none;\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/max_1200/dc414d47022465.586df3e56456e.gif\"></p>",
			"cover": "img\/covers\/vrbfoto.png",
			"tags":"VRB Foto 360 photo sharing application for the Gear VR.",
			"previous":"",
			"next":"",
			"year":"2016",
			"productpage":"https://www.oculus.com/experiences/gear-vr/1297827283571813/",
			"demo":"../vrbis",
			"filters":"ux-design vis-design ux-design interaction-design emerging-tech development",
			"featured":"inline",
			"color":"#be7cb5",
			"company":"VRB / Samsung Accelerator",
			"role":"VR Generalist",
			"brief":"VRB Foto is a 360 Photo viewer that allows users to share and augment their photos. ",
			"content1":"<div class=\"left\"><h1>Grenu</h1></div> <div class=\"right\"><p>I worked on the VRB team at the Samsung accelerator (now known as Samsung Next) where we created an application for the Gear VR called VRB Foto. I assisted the Project Manager and Creative Director in exploring different user interfaces to interact with the VRB Foto world. Specifically, I worked with the \"grenu,\" VRB Foto's menu system. We wanted to create a menu that could scale easily to add more and more effects.<br><br><img class=\"nodrop modalize\" src=\"../img/foto1.gif\"></p></div>",
			"content2":"<div class=\"left\"><h1>Website</h1></div> <div class=\"right\"><p>I also designed the web portal for VRB Foto which you can view here. The most challenging part about the web portal was deciding how users would preview photospheres.</p></div>",
			"content3":"<div class=\"left\"><h1></h1></div> <div class=\"right\"><img class=\"nodrop modalize\" src=\"../img/foto2.gif\"></div>",
			"content4":"<div class=\"left\"><h1>Acquisition</h1></div> <div class=\"right\"><p>The VRB team was recently acquired by Samsung proper and has now relocated to San Francisco. Read more details <a href=\"https://techcrunch.com/2017/06/16/samsung-quietly-acquired-vr-app-studio-vrb-sources-say-for-5-5m/\">here</a></p></div>"
		}, {
			"index": "blue",
			"name": "Body Labs Blue",
			"url": "https:\/\/www.behance.net\/gallery\/41917453\/Body-Labs-Blue",
			"productpage": "https://www.bodylabs.com/solutions/spectrum/blue/",
			"video":"<iframe src=\"https:\/\/www.youtube.com\/embed\/33qBnhdWQ7w\" frameborder=\"0\" allowfullscreen><\/iframe>",
			"description": "<br><br><p>Although we want users to trust our predictive algorithm, we also want to enable them to add more specific information accurately. <br><br><center><a target=\"_blank\" href=\"https:\/\/www.bodylabs.com\/solutions\/spectrum\/blue\/\">View Blue Here<\/a><\/center><br><br><img class=\"fullw\" src=\"http:\/\/claremarie.info\/img\/portfolio\/blscreenshot.png\"><\/p>",
			"cover": "img\/covers\/blue.png",
			"tags":"Interface for creating virtual bodies from measurements.",
			"previous":"",
			"next":"",
			"year":"2016",
			"filters":"ux-design interaction-design",
			"featured":"none",
			"color":"#28b2c9",
			"company":"Body Labs",
			"role":"UX/UI Designer and Developer",
			"duration":"4 Months",
			"brief":"This is a project I lead as a UX Designer at Body Labs. Essentially, Body Labs Blue is a tool for creating custom clothing through six key measurements. The main goal of this product is to allow users to feel confident buying custom clothing when entering only a few measurements.",
			"content1":"<div class=\"left\"><h1>Product Description</h1></div> <div class=\"right\"><p>Through an easily embedded Web interface, Body Labs Blue uses artificial intelligence (AI) and machine learning algorithms to reference just the height and weight of your customers to predict 19 highly accurate additional measurements ideal for custom clothing or sizing recommendations. To help ensure accuracy, your customers can also refine six-key measurements predicted by Blue. This enables your business to deliver clothing customization and standardization that scales for any purchase volume or web traffic.</p></div>",
			"content3":"<div class=\"left\"><h1>Product Demo</h1></div> <div class=\"right\"><video controls loop autoplay width=\"100%\"><source src=\"../video/blue.mp4\" type=\"video/mp4\"></div>",
			"content2":"<div class=\"left\"><h1>Prototypes</h1></div> <div class=\"right\"><video controls loop autoplay width=\"100%\"><source src=\"../video/blueprototypes.mp4\" type=\"video/mp4\"></div>"
		}, {
			"index": "holojam",
			"name": "Holojam",
			"url": "https:\/\/www.behance.net\/gallery\/35388195\/Holojam",
			"video":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/zB9Vw1vPo20\" frameborder=\"0\" allowfullscreen></iframe>",
			"description": "<p><br><center><a href=\"http:\/\/mrlholojam.tumblr.com\">Official Website<\/a><\/center>",
			"cover": "img\/covers\/holojam.png",
			"tags":"Multi-user VR drawing experience.",
			"previous":"",
			"next":"",
			"year":"2015",
			"filters":"project-management ux-design emerging-tech",
			"featured":"none",
			"color":"#9974af",
			"role":"User Experience Designer",
			"group":"NYU Media Research Lab",
			"demos":"SIGGRAPH 2015",
			"brief":"This is an experience I helped design and manage at the NYU Media Research Lab under Ken Perlin. We created an experience where up to five people can draw in virtual reality together.",
			"content1":"<div class=\"left\"><h1>About the Experience</h1></div> <div class=\"right\"><p>Up to five people share virtual space with untethered headsets and see each other as stylized avatars. They draw shapes in the air with their magic wands and contribute to a persistent three-dimensional sculptural art-work. <a href=\"http://mrlholojam.tumblr.com/detailed-description\">Full Description Here</a></p></div>",
			"content2":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Connor Defanti, Zach Cimafonte, Laura Juo-Hsin Chen, Sebastian Herscher, Will Field-Thompson, Daren Liu, David Lobser, Ken Perlin.</p></div>",
			"content3":"<div class=\"left\"><h1>Press</h1></div> <div class=\"right\"><p>Motherboard, MIT Technology Review, UploadVR, WSN, VRR</p></div>"
		}, {
			"index": "motivate",
			"name": "Motivate - Body Labs Hackathon Submission",
			"url": "https:\/\/www.behance.net\/gallery\/25338009\/Motivate-Body-Labs-Hackathon-Submission",
			"video":"<iframe src=\"https://player.vimeo.com/video/123574576\" width=\"500\" height=\"281\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>",
			"description": "<p>This is my team's submission for the Body Labs Hackathon @ NYU with Yoland Yan and Chris Jimenez. This project was done over the course of 10 hours and landed me a UX position at Body Labs. Motivate is a social fitness platform which utilizes body scanning to help you explore the fitness routines of individuals with similar body shapes.<br><br>Check out the interactive demo <a href=\"https:\/\/marvelapp.com\/c7ah14g\/screen\/21277833\">here<\/a>.<\/p>",
			"cover": "img\/covers\/motivate.jpg",
			"tags":"Mobile UI for a social fitness platform.",
			"previous":"",
			"next":"",
			"year":"2015",
			"filters":"ux-design vis-design interaction-design project-management",
			"featured":"none",
			"color":"#383b46",
			"duration":"10 Hours",
			"brief":"This was my team's submission for the Body Labs Hackathon @ NYU. This project was done over the course of 10 hours and landed me a UX/UI position at Body Labs from 2015-2016. Check out the demo <a target=\"_blank\" href=\"https://marvelapp.com/c7ah14g/screen/21277833\">here</a>.",
			"content1":"<div class=\"left\"><h1>Screens</h1></div> <div class=\"right\"><img class=\"nodrop modalize\" src=\"https://mir-s3-cdn-cf.behance.net/project_modules/1400/fd7fd425338009.5877d5963e673.png\"></div>",
			"content2":"<div class=\"left\"><h1>Team</h1></div> <div class=\"right\"><p>Chris Jimenez and Yoland Yan.</p></div>"
		}, {
			"index": "graphicdesign",
			"name": "Misc Graphic Design",
			"url": "",
			"video":"",
			"description": "",
			"cover": "img\/covers\/graphicdesign.png",
			"tags":"Miscellaneous graphic design projects.",
			"previous":"",
			"next":"",
			"year":"Various",
			"filters":"vis-design",
			"featured":"none",
			"color":"#c4315f",
			"client":"Misc.",
			"brief":"These are some of my favorite graphic design projects I have done over the years.",
			"content1":"<div class=\"left\"><h1>VRCade @ Barcade</h1><p>Advertisement for event at the Samsung Accelerator.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/1.png\"></div>",
			"content2":"<div class=\"left\"><h1>Spotlight Mailer</h1><p>Advertisement for the 2014 Spotlight competition.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/2.png\"></div>",
			"content3":"<div class=\"left\"><h1>Globall Artwork</h1><p>Artwork for the NYU Welcome Week Dance Globall.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/3.png\"></div>",
			"content4":"<div class=\"left\"><h1>Just Keep Swimming</h1><p>Personal project.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/4.png\"></div>",
			"content5":"<div class=\"left\"><h1>UVL Postcard</h1><p>Advertisement for NYU's full school Ultra Violet Live talent show.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/5.jpg\"></div>",
			"content6":"<div class=\"left\"><h1>Day of Service Poster</h1><p>For NYU's Inter-Residence Hall Council.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/6.jpg\"></div>",
			"content7":"<div class=\"left\"><h1>Elephant Doodle</h1><p>Personal Project.</p></div> <div class=\"right\"><img class=\"modalize\" src=\"../img/graphicdesign/7.png\"></div>"

			
		}

	]

}